using System.Collections.Generic;
using Cysharp.Threading.Tasks;// System.Threading.Tasks;
using UnityEngine.Rendering;
using UnityEngine;
namespace EyE.NNET
{
    /// <summary>
    /// This Variant of the NetLayer base class overrides the ComputeOutput functions to use a compute shader, rather than process it all on the cpu.
    /// It also has a couple of new functions called ComputeLayer.  These function will NOT automatically pass data back to the cpu after processing.  This allows data to be passed from one layer to the next, while staying on the GPU, which enhances performance.  
    ///     The version that has no parameter will use the output generated by the prious layer, as stored on the GPOU.  
    ///     The other version, which takes inputs, is really only intended for the first layer, to get the external input into the net.
    /// To get the output data back to the CPU use the GetLastComputedOutput function.  While the ComputeOutput functions do this automatically, every cycle, the ComputeLayer versions wont.
    /// Alternatively, you can use the GetGPUData function to pull all the information about the layer back to the cpu.  This can use useful if you want to visualize or display the network, somehow.
    /// </summary>
    public class ComputeShaderLayer : NetLayer, System.IDisposable
    {
        // Reference to the compute shader asset
        public ComputeShader computeShader;
        public bool computeShaderIsSinglePass = true;
         
        //these string are exact copies of function identifiers in the compute shader code
        private static readonly string[] singlePassComputeLayerKernalNames = new string[4] { "ComputeLayerNone", "ComputeLayerReLU", "ComputeLayerSigmoid", "ComputeLayerTanh01" };

        private static readonly string resetZeroOutputKernalName = "ZeroOutputs";
        private static readonly string[] biasAndActivationkernelNames = new string[4] { "ApplyBiasAndActivationNone", "ApplyBiasAndActivationReLU", "ApplyBiasAndActivationSigmoid", "ApplyBiasAndActivationTanh01" };
        private static readonly string computeWeightSumKernalName = "OneDimComputeLayerWeightedSum";
        private static readonly string backPrepegateZeroStartKernalName = "BackPropegateZeroErrorsStart";
       // private static readonly string[] backPrepegateKernalNames = new string[4] { "BackPropegateNoneSinglePass", "BackPropegateReLuSinglePass", "BackPropegateSigmoidSinglePass", "BackPropegateTanh01SinglePass", };
        
        private static readonly string[] backPrepegateMultiPassKernalNames = new string[4] { "BackPropegateNoneComputeActivationDerivatiePass", "BackPropegateReLuComputeActivationDerivatiePass", "BackPropegateSigmoidComputeActivationDerivatiePass", "BackPropegateTanh01ComputeActivationDerivatiePass", };
        private static readonly string BackPropegateInputPassName = "BackPropegateInputPass";

        int singlePassComputeLayerKernalIndex;
        int resetZeroOutputKernalIndex;
        int computeWeightSumKernalIndex;
        int computeAddBiasAndActivationKernelIndex;
        int BackPropegateBiasPassKernalIndex;
        int BackPropegateInputPassKernalIndex;
        int backPropZeroKernalIndex;
        //int backPropSinglePassKernalIndex;


        // Buffers for inputs, outputs, weights, and biases
        private ComputeBuffer inputBuffer;
        public ComputeBuffer outputBuffer;
        private ComputeBuffer weightsBuffer;
        private ComputeBuffer biasesBuffer;

        private ComputeBuffer propegatedErrorBuffer;
        public ComputeBuffer sourceErrorBuffer;
        public ComputeBuffer activationDerivativeBuffer;
        private ComputeBuffer weightsErrorBuffer;
        private ComputeBuffer biasesErrorBuffer;

        /// <summary>
        /// 
        /// </summary>
        /// <param name="computeShader"></param>
        /// <param name="numNeurons"></param>
        /// <param name="numInputs"></param>
        /// <param name="activationFunction"></param>
        /// <param name="inputBuffer">may contain a referene to the output buffer of the previous layer.  This way the data can stay on the GPU</param>
        public ComputeShaderLayer(ComputeShader computeShader,int numNeurons, int numInputs, ActivationFunction activationFunction, bool computeShaderIsSinglePass = true, ComputeShaderLayer previousLayer =null) :base(numNeurons,  numInputs,  activationFunction)
        {
            this.computeShader = ComputeShader.Instantiate<ComputeShader>(computeShader);
            this.computeShaderIsSinglePass = computeShaderIsSinglePass;
            if (previousLayer != null)
            {
                this.inputBuffer = previousLayer.outputBuffer;
                this.propegatedErrorBuffer = previousLayer.sourceErrorBuffer;
            }

            InitBuffers();
        }

        public ComputeShaderLayer(ComputeShader computeShader,NetLayer source, bool computeShaderIsSinglePass = true,ComputeShaderLayer previousLayer = null) : base(source)
        {
            this.computeShader = ComputeShader.Instantiate<ComputeShader>(computeShader);
            this.computeShaderIsSinglePass = computeShaderIsSinglePass;
            if (previousLayer != null)
            {
                this.inputBuffer = previousLayer.outputBuffer;
                this.propegatedErrorBuffer = previousLayer.sourceErrorBuffer;
            }
            InitBuffers();
        }


        void InitBuffers()
        {
            if (computeShaderIsSinglePass)
                this.singlePassComputeLayerKernalIndex = computeShader.FindKernel(singlePassComputeLayerKernalNames[(int)activationFunction]);
            else
            {
                this.computeWeightSumKernalIndex = computeShader.FindKernel(computeWeightSumKernalName);
                this.resetZeroOutputKernalIndex = computeShader.FindKernel(resetZeroOutputKernalName);
                this.computeAddBiasAndActivationKernelIndex = computeShader.FindKernel(biasAndActivationkernelNames[(int)activationFunction]);
            }
            backPropZeroKernalIndex= computeShader.FindKernel(backPrepegateZeroStartKernalName);
//            backPropSinglePassKernalIndex= computeShader.FindKernel(backPrepegateKernalNames[(int)activationFunction]);
            BackPropegateBiasPassKernalIndex = computeShader.FindKernel(backPrepegateMultiPassKernalNames[(int)activationFunction]);
            BackPropegateInputPassKernalIndex = computeShader.FindKernel(BackPropegateInputPassName);

            // Create buffers for inputs, outputs, weights, and biases during initialization
            //Debug.Log("Initializing Layer Buffers " + ((inputBuffer == null) ? "creating new inputBuffer":"provided existing buffer for input"));
            if (inputBuffer == null) 
                inputBuffer = new ComputeBuffer(NumInputs, sizeof(float)); //if input buffer was not passed in, create one
            outputBuffer = new ComputeBuffer(NumNeurons, sizeof(float));
            weightsBuffer = new ComputeBuffer(NumNeurons * NumInputs, sizeof(float));
            biasesBuffer = new ComputeBuffer(NumNeurons, sizeof(float));

            if(propegatedErrorBuffer == null) 
                propegatedErrorBuffer = new ComputeBuffer(NumInputs, sizeof(float));
            activationDerivativeBuffer = new ComputeBuffer(NumNeurons, sizeof(float));
            sourceErrorBuffer = new ComputeBuffer(NumNeurons, sizeof(float));

            weightsErrorBuffer = new ComputeBuffer(NumNeurons * NumInputs, sizeof(float));
            biasesErrorBuffer= new ComputeBuffer(NumNeurons, sizeof(float));

            //assign compute buffers to compute shader
            if (!computeShaderIsSinglePass)
            {
                computeShader.SetBuffer(computeWeightSumKernalIndex, "inputBuffer", inputBuffer);

                computeShader.SetBuffer(computeWeightSumKernalIndex, "weightBuffer", weightsBuffer);
                computeShader.SetBuffer(computeAddBiasAndActivationKernelIndex, "biasBuffer", biasesBuffer);

                computeShader.SetBuffer(computeAddBiasAndActivationKernelIndex, "outputBuffer", outputBuffer);
                computeShader.SetBuffer(computeWeightSumKernalIndex, "outputBuffer", outputBuffer);
                computeShader.SetBuffer(resetZeroOutputKernalIndex, "outputBuffer", outputBuffer);
            }
            else
            {
                computeShader.SetBuffer(singlePassComputeLayerKernalIndex, "weightBuffer", weightsBuffer);
                computeShader.SetBuffer(singlePassComputeLayerKernalIndex, "inputBuffer", inputBuffer);
                computeShader.SetBuffer(singlePassComputeLayerKernalIndex, "biasBuffer", biasesBuffer);
                computeShader.SetBuffer(singlePassComputeLayerKernalIndex, "outputBuffer", outputBuffer);
            }

            /////  Set compute shader values and inputs.
            computeShader.SetInt("numInputs", NumInputs);
            computeShader.SetInt("numNeurons", NumNeurons);

            SetBackPropBuffers(backPropZeroKernalIndex);
            SetBackPropBuffers(BackPropegateBiasPassKernalIndex);
            SetBackPropBuffers(BackPropegateInputPassKernalIndex);

          //  SetBackPropBuffers(backPropSinglePassKernalIndex);

            SetShaderWeightsAndBiasData();
        }
        void SetBackPropBuffers(int kernelID)
        {
            computeShader.SetBuffer(kernelID, "progegatedErrorBuffer", propegatedErrorBuffer);
          //  if(kernelID!=backPropZeroKernalIndex)
                computeShader.SetBuffer(kernelID, "activationDerivativeBuffer", activationDerivativeBuffer);


            computeShader.SetBuffer(kernelID, "progegatedErrorBuffer", propegatedErrorBuffer);
            computeShader.SetBuffer(kernelID, "sourceErrorBuffer", sourceErrorBuffer);
            computeShader.SetBuffer(kernelID, "weightBuffer", weightsBuffer);
            computeShader.SetBuffer(kernelID, "biasBuffer", biasesBuffer);
            computeShader.SetBuffer(kernelID, "inputBuffer", inputBuffer);
            computeShader.SetBuffer(kernelID, "outputBuffer", outputBuffer);

            computeShader.SetBuffer(kernelID, "biasErrorBuffer", biasesErrorBuffer);
            computeShader.SetBuffer(kernelID, "weightErrorBuffer", weightsErrorBuffer);


        }
        private bool disposed = false;

        public void Dispose()
        {
            Dispose(true);
            System.GC.SuppressFinalize(this);
        }

        protected virtual void Dispose(bool disposing)
        {
            if (!disposed)
            {
                if (disposing)
                {
                    inputBuffer?.Dispose();
                    outputBuffer?.Dispose();
                    weightsBuffer?.Dispose();
                    biasesBuffer?.Dispose();

                    propegatedErrorBuffer?.Dispose();
                    sourceErrorBuffer?.Dispose();
                }
                disposed = true;
            }
        }
        void SetShaderWeightsAndBiasData()
        {
            //// assign values/initialize buffer data
            // Set the weights in the weights buffer (flatten the weights array)
            weightsBuffer.SetData(weights);
            // Set the biases in the biases buffer
            biasesBuffer.SetData(biases);
            // we don't need to set data for the output buffer, we will GET it after processing.
            // we don't need to set input data here, that will be done just before processing.

        }

        // Override the ComputeOutputs method to use the compute shader for processing
        // this variant set and gets the data on the gpu, for cpu use
        // it is intended to be used on only the first layer of the NeuralNet
        async public override UniTask<float[]> ComputeOutputs(float[] inputs)
        {
            this.inputs = inputs;
            if (inputs.Length != NumInputs)
                throw new System.ArgumentException("Invalid number of inputs passed to ComputeShaderLayer.ComputeOutputs.");

            // Set the inputs in the input buffer
            inputBuffer.SetData(inputs);

            DispatchComputeShader();
            await GetLastComputedOutput();

            return outputs;
        }
        // Override the ComputeOutputs method to use the compute shader for processing
        // this variant does NOT set and DOES gets the data on the gpu, for cpu use
        // it is intended to be used on all layers AFTER the first layer of the NeuralNet
        async public UniTask<float[]> ComputeOutputs()
        {
            DispatchComputeShader();
            await GetLastComputedOutput();
            return outputs;
        }

        //Launches/dispatches the compute layer process, and returns immidiately.  This variant assigns to, and then leaves the data on the gpu, and does not get it for cpu use after computation
        // it is intended to be used on the first layer of the NeuralNet
        public void ComputeLayer(float[] inputs)
        {
            if (inputs.Length != NumInputs)
                throw new System.ArgumentException("Invalid number of inputs passed to ComputeShaderLayer.ComputeOutputs.");
            this.inputs = inputs;
            // Set the inputs in the input buffer
            inputBuffer.SetData(inputs);
            DispatchComputeShader();
            return;
        }
        //Launches/dispatches the compute layer process, and returns immidiately.  This variant does not even assign data to the gpu, and it leaves the data there, not getting it for cpu use after computation
        // it is intended to be used on all layers AFTER the first layer of the NeuralNet
        public void ComputeLayer()
        {
            DispatchComputeShader();
            return;
        }
        // specifically get data from the GPU for gpu use, inteded for use with ComputeLayer functions. ComputeOutputs functions do this automatically, every time.
        // it is intended to be called on the last layer of a neural net that uses the ComputeLayer functions, to get the final output as a float[]
        async public UniTask<float[]> GetLastComputedOutput()
        {
            await GetFloatArrayFromBuffer(outputBuffer, outputs);
            //lastOutputs = outputs;
            return outputs;
        }
        async public UniTask GetGPUData()
        {
            if (requests.Count > 0) return; //already in the process of waiting for requested data
            RequestGPUData();
            await WaitForGPUData();
        }
        List<UnityEngine.Rendering.AsyncGPUReadbackRequest> requests = new List<UnityEngine.Rendering.AsyncGPUReadbackRequest>();  //list of requests, one for each buffer
        public void RequestGPUData()
        {
            if (requests.Count > 0) return; //already in the process of waiting for requested data
            // Add all the readback requests to the list
            requests.Add(AsyncGPUReadback.Request(inputBuffer));
            requests.Add(AsyncGPUReadback.Request(outputBuffer));
            requests.Add(AsyncGPUReadback.Request(weightsBuffer));
            requests.Add(AsyncGPUReadback.Request(biasesBuffer));
            requests.Add(AsyncGPUReadback.Request(propegatedErrorBuffer));
            requests.Add(AsyncGPUReadback.Request(sourceErrorBuffer));

            requests.Add(AsyncGPUReadback.Request(biasesErrorBuffer));
            requests.Add(AsyncGPUReadback.Request(weightsErrorBuffer));

        }
        async public UniTask WaitForGPUData()
        {
            if (requests.Count == 0) return; //no pending requests
            // Wait for all requests to complete
            int requestsCount = requests.Count;
            for(int i=0;i<requestsCount;i++)
            {
                while (!requests[i].done)
                    await UniTask.Yield();
            }
            
            if (inputs == null)
                inputs = new float[NumInputs];
            inputBuffer.GetData(inputs);
            outputBuffer.GetData(outputs);
            weightsBuffer.GetData(weights);
            biasesBuffer.GetData(biases);
            
            propegatedErrorBuffer.GetData(propagatedErrors);
            sourceErrorBuffer.GetData(sourceErrors);
            biasesErrorBuffer.GetData(biasErrors);
            weightsErrorBuffer.GetData(weightsErrors);
            requests.Clear();
        }

        //not efficient at getting more than one buffer at a time since it yields until the request is ready.
        async UniTask GetFloatArrayFromBuffer(ComputeBuffer buffer,float[] array)
        {
          //  Debug.Log("getting buffer data");

            UnityEngine.Rendering.AsyncGPUReadbackRequest request = UnityEngine.Rendering.AsyncGPUReadback.Request(buffer);
            
            while (!request.done)
              await UniTask.Yield();
            buffer.GetData(array);
          //  Debug.Log("got buffer data");
        }
        
        /// <summary>
        /// This function dispatches the compute shaders
        /// </summary>
        /// <returns></returns>
        void DispatchComputeShader()
        {
            if (inputBuffer == null) throw new System.ArgumentException("Shader layer invoked without input buffer assigned.  Call ComputeLayer(float[] inputs) to pass in input values, or create the layer with an input buffer provided.");
            if (computeShader == null)
            {
                Debug.Log("Null ComputeShader Aborting Dispatch");
                return;
            }
            // Set the compute shader kernel and dispatch it
            if (!computeShaderIsSinglePass)
            {
                /*UnityEngine.Rendering.CommandBuffer commandBuffer = new UnityEngine.Rendering.CommandBuffer();
                commandBuffer.DispatchCompute(computeShader, resetZeroOutputKernalIndex, NumNeurons, 1, 1);//first we zero the output buffer contents
                commandBuffer.DispatchCompute(computeShader, computeWeightSumKernalIndex, NumNeurons * NumInputs, 1, 1);//next we compute all the input values * connecting weights, summing the results to its neuron ouput
                commandBuffer.DispatchCompute(computeShader, computeAddBiasAndActivationKernelIndex, NumNeurons, 1, 1);//next we apply the activation function and neuron's bias to the inputsum and so, generate the final output of eah neuron activation upon input sum
                Graphics.ExecuteCommandBuffer(commandBuffer);
                commandBuffer.Release();*/
                //the multi pass method allows for greater parallelization as all input connects can be processed in parallel
                computeShader.Dispatch(resetZeroOutputKernalIndex, NumNeurons, 1,1);//first we zero the output buffer contents
                computeShader.Dispatch(computeWeightSumKernalIndex, NumNeurons * NumInputs, 1,1);//next we compute all the input values * connecting weights, summing the results to its neuron ouput
                computeShader.Dispatch(computeAddBiasAndActivationKernelIndex, NumNeurons, 1, 1);//next we apply the activation function and neuron's bias to the inputsum and so, generate the final output of eah neuron activation upon input sum
            }
            else // the single pass method can paralleleize neurons, but not the connections to those neurons (must loop for each neuron)
            {
                //Debug.Log("Dispatching kernel:" + singlePassComputeLayerKernalIndex);
                computeShader.Dispatch(singlePassComputeLayerKernalIndex, NumNeurons, 1, 1);
            }
           // await Task.Yield();
            return;
        }
        //TODO: add clipping threshold to layer compute shader code
        async public override UniTask<float[]> Backpropagate(float[] ignored, float[] errors, float learningRate,float gradientClippingThreshold=0)
        {
            if (computeShader == null) return new float[0];
            computeShader.SetFloat("learningRate", learningRate);
            sourceErrors = errors;
            sourceErrorBuffer.SetData(sourceErrors);
            computeShader.SetBuffer(backPropZeroKernalIndex, "progegatedErrorBuffer", propegatedErrorBuffer);
            computeShader.SetBuffer(BackPropegateBiasPassKernalIndex, "progegatedErrorBuffer", propegatedErrorBuffer);
            computeShader.SetBuffer(BackPropegateInputPassKernalIndex, "progegatedErrorBuffer", propegatedErrorBuffer);

            computeShader.Dispatch(backPropZeroKernalIndex, NumInputs, 1, 1);

            //"single" pass version- fails because multipe threads trying to write to same error bufer element
            //computeShader.Dispatch(backPropSinglePassKernalIndex, NumNeurons, 1, 1);
            
            //multi pass version
            computeShader.Dispatch(BackPropegateBiasPassKernalIndex, NumNeurons, 1, 1);
            computeShader.Dispatch(BackPropegateInputPassKernalIndex, NumInputs,1, 1);

            await GetFloatArrayFromBuffer(propegatedErrorBuffer, propagatedErrors);
           // await GetGPUData();
            
            //float[] ret=base.Backpropagate(inputs, errors, learningRate);
            //SetShaderWeightsAndBiasData();//we modified these with backpropegate- update data on GPU
            return propagatedErrors;
        }
        //this version called on last layer only
        async public UniTask GPUBackpropagate(float[] errors, float learningRate)
        {
           // if (computeShader == null) return;
         //   computeShader.SetFloat("learningRate", learningRate);
            sourceErrors = errors;
            sourceErrorBuffer.SetData(sourceErrors);
            await GPUBackpropagate(learningRate);
        }
        //this called on all layers before last layer (iterated AFTER last layer during backpropegation)
        async public UniTask GPUBackpropagate(float learningRate)
        {
            if (computeShader == null) return;
            computeShader.SetFloat("learningRate", learningRate);

            computeShader.Dispatch(backPropZeroKernalIndex, NumInputs, 1, 1);

            //"single" pass version- fails because multipe threads trying to write to same error bufer element
            //computeShader.Dispatch(backPropSinglePassKernalIndex, NumNeurons, 1, 1);
            //multi pass version
            computeShader.Dispatch(BackPropegateBiasPassKernalIndex, NumNeurons, 1, 1);
            computeShader.Dispatch(BackPropegateInputPassKernalIndex, NumInputs, 1, 1);
        }

    }
}